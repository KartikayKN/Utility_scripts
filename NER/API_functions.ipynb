{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc4013b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c043b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import spacy\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "from google.cloud import vision\n",
    "import io\n",
    "import time\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import boto3\n",
    "import logging\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import gc\n",
    "from database import update_doc_type\n",
    "\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'gcp/googlecreds.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f9fb0",
   "metadata": {},
   "source": [
    "### KeyValue (extract and map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb515174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    current_Key = \"\"\n",
    "    dic = {}\n",
    "    key_cnt = 0\n",
    "    val_cnt = 0\n",
    "    current_val = \"\"\n",
    "    text = text.replace(\"\\n\" , \"\")\n",
    "#     dic['Text'] = text\n",
    "    doc = nlp_ner(text)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ == \"KEY\"):\n",
    "            key_cnt +=1\n",
    "            current_Key = ent.text\n",
    "            dic[current_Key]= \"\"\n",
    "        elif (ent.label_ == \"VALUE\"):\n",
    "            val_cnt +=1\n",
    "            current_val = ent.text\n",
    "            if(current_Key!=\"\"):\n",
    "                dic[current_Key] = ent.text\n",
    "                current_Key=\"\"\n",
    "    if val_cnt == 1 and key_cnt == 1 and current_Key!=\"\" :\n",
    "        dic[current_Key]= current_val\n",
    "    return dic\n",
    "\n",
    "\n",
    "def get_master_key_val(key_val_map):\n",
    "    dic = {}\n",
    "    duplicate_keys = []\n",
    "    for key in key_val_map.keys():\n",
    "        for x in key_val_map[key].keys():\n",
    "            if x not in dic.keys() and x not in duplicate_keys and x not in duplicates_label_list:\n",
    "                dic[x] = key_val_map[key][x]\n",
    "            elif x not in duplicate_keys and x not in duplicates_label_list:\n",
    "                dic.pop(x)\n",
    "                duplicate_keys.append(x)\n",
    "    return dic\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a40c31",
   "metadata": {},
   "source": [
    "### Image (Bbox detection to text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(model, path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    scores = outputs['instances'].scores.cpu().numpy().tolist()\n",
    "    boxes = outputs['instances'].pred_boxes.tensor.cpu().numpy().tolist()\n",
    "    labels = outputs['instances'].pred_classes.cpu().numpy().tolist()\n",
    "\n",
    "#     upload_to_s3(output_path, getOutputBucket())\n",
    "#     logger.info('Uploaded output to S3.')\n",
    "\n",
    "    del image\n",
    "    gc.collect()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    filename = Path(path).stem\n",
    "    data = {'filename': filename, 'boxes': boxes, 'scores': scores, 'labels': labels}\n",
    "    return data\n",
    "\n",
    "\n",
    "def detectText(path):\n",
    "\n",
    "    vertexList = []\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.text_detection(image=image)\n",
    "    # print(response)\n",
    "    texts = response.text_annotations\n",
    "    bool = False\n",
    "    complete_text = ''\n",
    "    for text in texts:\n",
    "        # print(text)\n",
    "\n",
    "        vertices = text.bounding_poly.vertices\n",
    "        if bool:\n",
    "            vertexList.append((text.description, vertices))\n",
    "        else:\n",
    "            complete_text = text.description\n",
    "            bool = True\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\n'.format(response.error.message))\n",
    "\n",
    "    return vertexList\n",
    "\n",
    "\n",
    "def create_text_list(vertexList, data):\n",
    "    detectionList = data['boxes']\n",
    "    labelList = data['labels']\n",
    "    labels = []\n",
    "    text_array = []\n",
    "    boxes = []\n",
    "    for i in range(len(detectionList)):\n",
    "        boundingBox = detectionList[i]\n",
    "        label = labelList[i]\n",
    "        text = ''\n",
    "        try:\n",
    "            for textGroup in vertexList:\n",
    "                vertexText = textGroup['text']\n",
    "                vertex = textGroup['border']\n",
    "\n",
    "                x1 = vertex.get('minX', 0)\n",
    "                y1 = vertex.get('minY', 0)\n",
    "                x2 = vertex.get('maxX', 0)\n",
    "                y2 = vertex.get('maxY', 0)\n",
    "                height = y2 - y1\n",
    "                width = x2 - x1\n",
    "\n",
    "                if (not (max(x1, boundingBox[0]) + width / 3 > min(x2, boundingBox[2]))) and \\\n",
    "                        (not (max(y1, boundingBox[1]) + height / 3 > min(y2, boundingBox[3]))):\n",
    "                    text += vertexText + ' '\n",
    "        except KeyError as e:\n",
    "            logger.info('Key Error:')\n",
    "            logger.error(e)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "\n",
    "        labels.append(label)\n",
    "        text_array.append(text)\n",
    "        boxes.append([boundingBox[0], boundingBox[1], boundingBox[2], boundingBox[3]])\n",
    "\n",
    "    return {\"label\": labels, \"text_data\": text_array, \"boxes\": boxes}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0a167",
   "metadata": {},
   "source": [
    "### Load Detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model_path = 'keyValue_detectron2.pth'\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.info(\"Downloading model from s3\")\n",
    "        get_check_point_file_from_s3(model_path)\n",
    "        get_check_point_file_from_s3('config_101.yaml')\n",
    "    model = get_model(model_path, 0.5, device, 'config_101.yaml')\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def get_model(model_path, threshold, device, config_path):\n",
    "    # Create config\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_path)\n",
    "    cfg.MODEL.DEVICE = device\n",
    "\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
    "\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "\n",
    "    return DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7659901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = load_model()\n",
    "    nlp_ner = spacy.load(\"./model-best\")\n",
    "    base_path = 'dir/images/'\n",
    "    json_list = []\n",
    "    for file in glob.glob(base_path + '/*.png'):\n",
    "        data = detection(model, file)\n",
    "        vertexList = detectText(file)\n",
    "        results = create_text_list(vertexList, data)\n",
    "        final_dic = {}\n",
    "        c = 0\n",
    "        for line in results['text_data']:\n",
    "            line = line replace(\"\\n\" , \"\")\n",
    "            dic = extract(line)\n",
    "            c = c + 1\n",
    "            bbox = \"BBOX\" + str(c)\n",
    "            final_dic[bbox] = dic\n",
    "        json_list.append(final_dic)\n",
    "    return json_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88458c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
